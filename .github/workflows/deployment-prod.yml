name: deployment-prod
on:
  workflow_dispatch: 

env:
  GH_REF: ${{ github.ref }} 
  aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  aws_region: ${{ secrets.AWS_REGION }}  

jobs:
  build: 
    runs-on: ubuntu-latest    
    steps: 
      # git checkout 
      - name: checkout code
        uses: actions/checkout@v3
      
      # set up docker buildx
      - name: set up docker buildx
        uses: docker/setup-buildx-action@v2

      # read env file from s3
      - uses: keithweaver/aws-s3-github-action@v1.0.0
        with:
          command: cp
          source: s3://traffic-monitor-env-s3-bucket/.env
          # destination:
          aws_access_key_id: ${{ env.aws_access_key_id }}
          aws_secret_access_key: ${{ env.aws_secret_access_key }}
          aws_region: ${{ env.aws_region }}

      # write s3 env to secrets
      - name: write to $github_env
        shell: bash
        run: cat .env | while read line || [[ -n $line ]]; do echo $line >> $GITHUB_ENV; done
          
      # login to prod aws ecr
      - name: login to aws ecr
        uses: docker/login-action@v2        
        with:
          registry: ${{ env.aws_dev_ecr}}
          username: ${{ env.aws_access_key_id }}
          password: ${{ env.aws_secret_access_key }}

      # bulid and push the docker image
      - name: docker build and push
        uses: docker/build-push-action@v2
        with:
          context: ./data-ingestion/kafka/
          push: true 
          tags: ${{ env.aws_dev_ecr }}:${{ github.sha }}

  prod:
    needs: build
    runs-on: ubuntu-latest    
    steps: 
      # git checkout 
      - name: checkout code
        uses: actions/checkout@v3

      # read env file from s3
      - uses: keithweaver/aws-s3-github-action@v1.0.0
        with:
          command: cp
          source: s3://traffic-monitor-env-s3-bucket/.env
          # destination:
          aws_access_key_id: ${{ env.aws_access_key_id }}
          aws_secret_access_key: ${{ env.aws_secret_access_key }}
          aws_region: ${{ env.aws_region }}

      - name: write to $github_env
        shell: bash
        run: cat .env | while read line || [[ -n $line ]]; do echo $line >> $GITHUB_ENV; done  

      # update the ecs task definition
      - name: update prod task definition 
        id: task-def
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: data-ingestion/kafka/task-definition.prod.json
          container-name: traffic-monitor-ecs-container
          image: ${{ env.aws_dev_ecr }}:${{ github.sha }}

      # configure your aws credentials
      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ env.aws_access_key_id }}
          aws-secret-access-key: ${{ env.aws_secret_access_key }}
          aws-region: ${{ env.aws_region }}

      # deploy prod ecs task definition
      - name: deploy prod ecs task definition
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition: ${{ steps.task-def.outputs.task-definition }}

      # set up python version 
      - name: set up python 
        uses: actions/setup-python@v4
        with: 
          python-version: '3.10'

      # install python dependencies
      - name: install dependencies 
        run: |
          python -m pip install --upgrade pip
          pip install -r data-transformation/dbt/requirements.txt
      
      - name: deploy dbt project 
        run: |          
          cd data-transformation/dbt/traffic_monitor         
          dbt deps      
          dbt run --target prod